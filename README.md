# VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models

<div align="center">

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Framework](https://img.shields.io/badge/Framework-PyTorch-orange.svg)](https://pytorch.org/)
[![Paper](https://img.shields.io/badge/Paper-ArXiv-red.svg)](https://arxiv.org/abs/2602.20999)

**[üè† Project Page](https://zbwwwwwwww.github.io/VII/)** | **[üìÑ Paper](https://arxiv.org/abs/2602.20999)** | **[üìä Dataset: COCO-I2VSafetyBench](https://huggingface.co/datasets/yonglixiang/COCO-I2VSafetyBench)** | **[üìä Dataset: ConceptRisk](https://huggingface.co/datasets/yonglixiang/ConceptRisk-Repro)**

</div>

---

## üöÄ Release Status

- [x] üìä **[2026.02] Datasets Released**: We have publicly released our evaluation datasets [**COCO-I2VSafetyBench**](https://huggingface.co/datasets/yonglixiang/COCO-I2VSafetyBench) and [**ConceptRisk**](https://huggingface.co/datasets/yonglixiang/ConceptRisk-Repro) on HuggingFace!
- [ ] üíª **[Coming Soon] Code & Benchmark Release**: The source code (including the core attack pipeline and the complete I2V safety evaluation benchmark scripts) will be fully open-sourced at a later stage. Stay tuned! üî•

---

## üìñ Abstract

  Image-to-Video (I2V) generation models, which condition video generation on reference images, have shown emerging visual instruction-following capability, allowing certain visual cues in reference images to act as implicit control signals for video generation. However, this capability also introduces a previously overlooked risk: adversaries may exploit visual instructions to inject malicious intent through the image modality. In this work, we uncover this risk by proposing Visual Instruction Injection (VII), a training-free and transferable jailbreaking framework that intentionally disguises the malicious intent of unsafe text prompts as benign visual instructions in the safe reference image. Specifically, VII coordinates a Malicious Intent Reprogramming module to distill malicious intent from unsafe text prompts while minimizing their static harmfulness, and a Visual Instruction Grounding module to ground the distilled intent onto a safe input image by rendering visual instructions that preserve semantic consistency with the original unsafe text prompt, thereby inducing harmful content during I2V generation. Empirically, our extensive experiments on four state-of-the-art commercial I2V models (Kling-v2.5-turbo, Gemini Veo-3.1, Seedance-1.5-pro, and PixVerse-V5) demonstrate that VII achieves Attack Success Rates of up to 83.5% while reducing Refusal Rates to near zero, significantly outperforming existing baselines.

---

## üé• Jailbreak Demo

*Examples of successful jailbreaks (Red-Teaming) generated by VII on commercial models.*

<table width="100%">
  <tr>
    <th width="25%">Kling-v2.5-turbo<br>(Violence and Threats)</th>
    <th width="25%">Gemini Veo-3.1-quality<br>(Hate and Extremism)</th>
    <th width="25%">Seedance-1.5-pro<br>(Illegal Activities)</th>
    <th width="25%">PixVerse-V5<br>(Sexual Content)</th>
  </tr>
  <tr>
    <td><img src="assets/kling_vio.gif" alt="Kling Demo" width="100%"></td>
    <td><img src="assets/veo_hate.gif" alt="Veo Demo" width="100%"></td>
    <td><img src="assets/seedance_ill.gif" alt="Seedance Demo" width="100%"></td>
    <td><img src="assets/pixverse_sex.gif" alt="PixVerse Demo" width="100%"></td>
  </tr>
</table>

---

## üíê Acknowledgements

This project incorporates evaluation logic and concepts from the following excellent open-source works. We thank the authors for their contributions to the AI Safety community.

* **[VBench]**: [Vchitect/VBench](https://github.com/Vchitect/VBench) for the NudeNet/Q16 ensemble evaluation logic.
* **[T2V-SafetyBench]**: [yalesong/T2V-SafetyBench](https://github.com/yalesong/T2V-SafetyBench) for the GPT-based semantic verification approach.

---

## ‚ö†Ô∏è Disclaimer

This project is designed for **AI Safety Research** and **Red Teaming** purposes. The goal is to identify vulnerabilities in current I2V models to build more robust defense mechanisms. 
* **Do not use this concept to generate harmful content for malicious purposes.**
* The generated content may be offensive or disturbing. Viewer discretion is advised.

---

## üîó Citation

If you find this work useful, please cite our paper:

```bibtex
@article{zheng2026vii,
  title={VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models},
  author={Zheng, Bowen and Xiang, Yongli and Hong, Ziming and Lin, Zerong and Yu, Chaojian and Liu, Tongliang and You, Xinge},
  journal={arXiv preprint arXiv:2602.20999},
  year={2026}
}
